{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'inRange'\n> Overload resolution failed:\n>  - lowerb is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'lowerb'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 128\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[32m    127\u001b[39m labeler = AutoLabelGenerator()\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[43mlabeler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_video\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvideos/1.mp4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# Create dataset.yaml\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mdataset/dataset.yaml\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mAutoLabelGenerator.process_video\u001b[39m\u001b[34m(self, video_path, output_dir)\u001b[39m\n\u001b[32m     28\u001b[39m hud = frame[\u001b[38;5;28mself\u001b[39m.hud_roi[\u001b[32m1\u001b[39m]:\u001b[38;5;28mself\u001b[39m.hud_roi[\u001b[32m1\u001b[39m]+\u001b[38;5;28mself\u001b[39m.hud_roi[\u001b[32m3\u001b[39m], \n\u001b[32m     29\u001b[39m           \u001b[38;5;28mself\u001b[39m.hud_roi[\u001b[32m0\u001b[39m]:\u001b[38;5;28mself\u001b[39m.hud_roi[\u001b[32m0\u001b[39m]+\u001b[38;5;28mself\u001b[39m.hud_roi[\u001b[32m2\u001b[39m]]\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 2. Find potential skill icons using color segmentation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m skill_boxes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfind_cooldown_skills\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhud\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# 3. OCR validation and annotation\u001b[39;00m\n\u001b[32m     35\u001b[39m frame_annotations = []\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 73\u001b[39m, in \u001b[36mAutoLabelGenerator.find_cooldown_skills\u001b[39m\u001b[34m(self, hud)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_cooldown_skills\u001b[39m(\u001b[38;5;28mself\u001b[39m, hud):\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# Convert to HSV for color detection\u001b[39;00m\n\u001b[32m     72\u001b[39m     hsv = cv2.cvtColor(hud, cv2.COLOR_BGR2HSV)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     mask = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43minRange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhsv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcooldown_color\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;66;03m# Find contours of blue regions\u001b[39;00m\n\u001b[32m     76\u001b[39m     contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
      "\u001b[31merror\u001b[39m: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'inRange'\n> Overload resolution failed:\n>  - lowerb is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'lowerb'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "class AutoLabelGenerator:\n",
    "    def __init__(self):\n",
    "        self.ocr = easyocr.Reader(['en'])\n",
    "        self.hud_roi = (0, 800, 1920, 280)  # Bottom HUD area for 1920x1080\n",
    "        self.skill_size = (80, 80)  # Expected skill icon size\n",
    "        self.cooldown_color = ([90, 50, 50], [120, 255, 255])  # HSV blue range\n",
    "        \n",
    "    def process_video(self, video_path, output_dir):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        frame_count = 0\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        annotations = {}\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "        \n",
    "            # 1. Extract HUD region\n",
    "            hud = frame[self.hud_roi[1]:self.hud_roi[1]+self.hud_roi[3], \n",
    "                      self.hud_roi[0]:self.hud_roi[0]+self.hud_roi[2]]\n",
    "            \n",
    "            # 2. Find potential skill icons using color segmentation\n",
    "            skill_boxes = self.find_cooldown_skills(hud)\n",
    "            \n",
    "            # 3. OCR validation and annotation\n",
    "            frame_annotations = []\n",
    "            for box in skill_boxes:\n",
    "                x1, y1, x2, y2 = box\n",
    "                skill_roi = hud[y1:y2, x1:x2]\n",
    "                \n",
    "                # Check for cooldown digits\n",
    "                if self.is_cooldown_active(skill_roi):\n",
    "                    class_id = 0  # Cooldown class\n",
    "                else:\n",
    "                    class_id = 1  # Ready class\n",
    "                \n",
    "                # Convert to YOLO format\n",
    "                img_height, img_width = hud.shape[:2]\n",
    "                x_center = (x1 + (x2-x1)/2) / img_width\n",
    "                y_center = (y1 + (y2-y1)/2) / img_height\n",
    "                width = (x2 - x1) / img_width\n",
    "                height = (y2 - y1) / img_height\n",
    "                \n",
    "                frame_annotations.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
    "                \n",
    "                # Save skill icon image\n",
    "                cv2.imwrite(f\"{output_dir}/frame{frame_count}_skill{len(frame_annotations)}.jpg\", skill_roi)\n",
    "            \n",
    "            # Save annotations\n",
    "            if frame_annotations:\n",
    "                with open(f\"{output_dir}/frame{frame_count}.txt\", 'w') as f:\n",
    "                    f.write('\\n'.join(frame_annotations))\n",
    "            \n",
    "            frame_count += 1\n",
    "            if frame_count % 100 == 0:\n",
    "                print(f\"Processed {frame_count}/{total_frames} frames\")\n",
    "        \n",
    "        cap.release()\n",
    "        return annotations\n",
    "    \n",
    "    def find_cooldown_skills(self, hud):\n",
    "        # Convert to HSV for color detection\n",
    "        hsv = cv2.cvtColor(hud, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv, *self.cooldown_color)\n",
    "        \n",
    "        # Find contours of blue regions\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        skill_boxes = []\n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            \n",
    "            # Filter by size and aspect ratio\n",
    "            if self.is_skill_icon(w, h):\n",
    "                # Expand to expected skill size\n",
    "                adjusted_box = (\n",
    "                    max(0, x - 10),\n",
    "                    max(0, y - 10),\n",
    "                    min(hud.shape[1], x + w + 10),\n",
    "                    min(hud.shape[0], y + h + 10)\n",
    "                )\n",
    "                skill_boxes.append(adjusted_box)\n",
    "        \n",
    "        return skill_boxes\n",
    "    \n",
    "    def is_skill_icon(self, w, h):\n",
    "        # Validate icon dimensions\n",
    "        return (self.skill_size[0]*0.8 < w < self.skill_size[0]*1.2 and \n",
    "                self.skill_size[1]*0.8 < h < self.skill_size[1]*1.2)\n",
    "    \n",
    "    def is_cooldown_active(self, skill_roi):\n",
    "        # Preprocess for OCR\n",
    "        processed = self.preprocess_skill(skill_roi)\n",
    "        \n",
    "        # OCR with EasyOCR\n",
    "        results = self.ocr.readtext(processed, allowlist='0123456789',\n",
    "                                   min_size=20, text_threshold=0.4)\n",
    "        \n",
    "        # Check for valid cooldown number\n",
    "        return any(self.is_valid_cooldown(r[1]) for r in results)\n",
    "    \n",
    "    def preprocess_skill(self, img):\n",
    "        # Enhance contrast and resize\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "        enhanced = clahe.apply(gray)\n",
    "        return cv2.resize(enhanced, (128, 128))\n",
    "    \n",
    "    def is_valid_cooldown(self, text):\n",
    "        # Validate detected numbers\n",
    "        try:\n",
    "            num = int(text)\n",
    "            return 1 <= num <= 300  # Reasonable cooldown range\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "# Usage\n",
    "labeler = AutoLabelGenerator()\n",
    "labeler.process_video(\"videos/1.mp4\", \"dataset\")\n",
    "\n",
    "# Create dataset.yaml\n",
    "with open(\"dataset/dataset.yaml\", 'w') as f:\n",
    "    f.write(\"\"\"path: dataset\n",
    "train: images/train\n",
    "val: images/val\n",
    "\n",
    "names:\n",
    "  0: cooldown\n",
    "  1: ready\n",
    "\n",
    "nc: 2\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lol_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
